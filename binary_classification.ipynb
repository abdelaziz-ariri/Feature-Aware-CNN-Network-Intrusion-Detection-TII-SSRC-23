{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "br_FbMcxoHwZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/master\\ SDIA/S3/Advanced\\ Topics\\ \\ Data\\ Science/dataset_binary.zip \\\n",
        " -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56uudaNAGeNs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LPW3CqcjGB2x"
      },
      "outputs": [],
      "source": [
        "X_train=pd.read_csv('/content/dataset/X_train.csv')\n",
        "X_test=pd.read_csv('/content/dataset/X_test.csv')\n",
        "X_val=pd.read_csv('/content/dataset/X_val.csv')\n",
        "y_train=pd.read_csv('/content/dataset/y_train.csv')\n",
        "y_test=pd.read_csv('/content/dataset/y_test.csv')\n",
        "y_val=pd.read_csv('/content/dataset/y_val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SFWDDLfU6Pln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79517ada-17b0-4777-dfdb-f142edef3a4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5076507, 1087824, 1087824)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(X_train), len(X_test), len(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pz_4ypjHQve"
      },
      "source": [
        "### **Encodage du label (obligatoire)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH_PNLrVGwC8"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    'Benign': 0,\n",
        "    'Malicious': 1\n",
        "}\n",
        "\n",
        "y_train.iloc[:, 0] = y_train.iloc[:, 0].map(label_map)\n",
        "y_val.iloc[:, 0]   = y_val.iloc[:, 0].map(label_map)\n",
        "y_test.iloc[:, 0]  = y_test.iloc[:, 0].map(label_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP7X31M4IFx_"
      },
      "source": [
        "### **Normalisation des features (TRÈS IMPORTANT)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJrSA4X0IKFp"
      },
      "source": [
        "On fit le scaler UNIQUEMENT sur le train\n",
        "(et on applique sur val/test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y2m1-yVcHdk9",
        "outputId": "7e657dc3-1519-4c32-c0ac-5ef8e276f633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 1️⃣ Fit uniquement sur le train\n",
        "scaler.partial_fit(X_train)\n",
        "\n",
        "# 2️⃣ Fonction de scaling par batch\n",
        "def scale_in_batches(X, scaler, batch_size=50_000):\n",
        "    X = X.values if hasattr(X, \"values\") else X\n",
        "    X_scaled = np.empty(X.shape, dtype=np.float32)\n",
        "\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        X_scaled[i:i+batch_size] = scaler.transform(X[i:i+batch_size])\n",
        "\n",
        "    return X_scaled\n",
        "\n",
        "# 3️⃣ Scaling sécurisé\n",
        "X_train_scaled = scale_in_batches(X_train, scaler)\n",
        "X_val_scaled   = scale_in_batches(X_val, scaler)\n",
        "X_test_scaled  = scale_in_batches(X_test, scaler)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2keUv9eJvtie"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "del X_train, X_val, X_test\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25yjeorIUNX",
        "outputId": "d0271e20-7e47-4ec2-8862-136cc3b6f5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : (5076507, 77) (5076507, 1)\n",
            "Val   : (1087824, 77) (1087824, 1)\n",
            "Test  : (1087824, 77) (1087824, 1)\n",
            "Labels uniques : [1 0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train :\", X_train_scaled.shape, y_train.shape)\n",
        "print(\"Val   :\", X_val_scaled.shape, y_val.shape)\n",
        "print(\"Test  :\", X_test_scaled.shape, y_test.shape)\n",
        "print(\"Labels uniques :\", y_train.iloc[:, 0].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD2ai9b0NQ2O"
      },
      "source": [
        "### **L’équilibrage se fait UNIQUEMENT sur le TRAIN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwXqSggqN4JZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# IMPORTANT : utiliser X_train_scaled\n",
        "train_df = pd.concat([\n",
        "    pd.DataFrame(X_train_scaled),\n",
        "    y_train.reset_index(drop=True)\n",
        "], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfNxLpR_7YG2"
      },
      "outputs": [],
      "source": [
        "# Nom de la colonne label\n",
        "label_col = train_df.columns[-1]\n",
        "df_benign    = train_df[train_df[label_col] == 0]\n",
        "df_malicious = train_df[train_df[label_col] == 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7_UccYLY5sh8",
        "outputId": "523c1300-207b-4b7d-a427-7fef09081f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "1    5075604\n",
            "0        903\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_df.iloc[:, -1].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkRBgPA5wSY5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#train_df,\n",
        "del X_train_scaled,train_df\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EtjoJdI6pxm",
        "outputId": "71539018-0069-4b18-ab5d-297d71ca9ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille cible par classe : 2000000\n"
          ]
        }
      ],
      "source": [
        "M =2000000\n",
        "print(\"Taille cible par classe :\", M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Er_wetEP7GhZ"
      },
      "outputs": [],
      "source": [
        "df_malicious_downsampled = resample(\n",
        "    df_malicious,\n",
        "    replace=False,      # sans duplication\n",
        "    n_samples=M,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybtDwiil78Y0"
      },
      "outputs": [],
      "source": [
        "df_benign_upsampled = resample(\n",
        "    df_benign,\n",
        "    replace=True,      # avec duplication\n",
        "    n_samples=M,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_gRgu6m-KzM"
      },
      "outputs": [],
      "source": [
        "train_balanced_df = pd.concat(\n",
        "    [df_benign_upsampled, df_malicious_downsampled]\n",
        ").sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "filAi5uZxnE0"
      },
      "outputs": [],
      "source": [
        "del df_benign, df_malicious, df_benign_upsampled, df_malicious_downsampled\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWadOGHx-gbo"
      },
      "outputs": [],
      "source": [
        "X_train_balanced = train_balanced_df.iloc[:, :-1].values\n",
        "y_train_balanced = train_balanced_df.iloc[:, -1].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uerWWiI3xzqg"
      },
      "outputs": [],
      "source": [
        "del train_balanced_df\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "collapsed": true,
        "id": "9P5j6-Mf-i1A",
        "outputId": "fdeadcdd-cff1-4f00-ab1e-0be2149808b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2000000\n",
              "1    2000000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pd.Series(y_train_balanced).value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iEj9cN6A2J"
      },
      "source": [
        "### **Implémentation FWM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pijdksFqE0vx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Fonction : calcul des poids FWM (TRAIN ONLY)\n",
        "def compute_fwm_weights(X, y, eps=1e-8):\n",
        "    \"\"\"\n",
        "    X : np.ndarray (n_samples, n_features)\n",
        "    y : np.ndarray (n_samples,)\n",
        "    \"\"\"\n",
        "\n",
        "    # Séparation des classes\n",
        "    X_0 = X[y == 0]\n",
        "    X_1 = X[y == 1]\n",
        "\n",
        "    # Moyennes par feature\n",
        "    mu_0 = np.mean(X_0, axis=0)\n",
        "    mu_1 = np.mean(X_1, axis=0)\n",
        "\n",
        "    # Variances par feature\n",
        "    std_0 = np.std(X_0, axis=0)\n",
        "    std_1 = np.std(X_1, axis=0)\n",
        "\n",
        "    # Score de séparabilité (article)\n",
        "    scores = np.abs(mu_1 - mu_0) / (std_0 + std_1 + eps)\n",
        "\n",
        "    # Normalisation\n",
        "    weights = scores / (np.sum(scores) + eps)\n",
        "\n",
        "    return weights.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrQdebbaBs-b",
        "outputId": "fc88525e-0f01-4e88-d3eb-2cd5719ccd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape des poids : (77,)\n"
          ]
        }
      ],
      "source": [
        "#Calcul des poids FWM (une seule fois)\n",
        "fwm_weights = compute_fwm_weights(\n",
        "    X_train_balanced,\n",
        "    y_train_balanced\n",
        ")\n",
        "\n",
        "print(\"Shape des poids :\", fwm_weights.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmO962-6B4Ks"
      },
      "outputs": [],
      "source": [
        "#Fonction : application FWM par batch (RAM SAFE)\n",
        "def apply_fwm_in_batches(X, weights, batch_size=50_000):\n",
        "    \"\"\"\n",
        "    X : np.ndarray (n_samples, n_features)\n",
        "    weights : np.ndarray (n_features,)\n",
        "    \"\"\"\n",
        "\n",
        "    X_fwm = np.empty_like(X, dtype=np.float32)\n",
        "\n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        X_fwm[i:i+batch_size] = X[i:i+batch_size] * weights\n",
        "\n",
        "    return X_fwm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxhCcp7WB_gb"
      },
      "outputs": [],
      "source": [
        "#Application FWM (train / val / test)\n",
        "X_train_fwm = apply_fwm_in_batches(X_train_balanced, fwm_weights)\n",
        "X_val_fwm   = apply_fwm_in_batches(X_val_scaled,   fwm_weights)\n",
        "X_test_fwm  = apply_fwm_in_batches(X_test_scaled,  fwm_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5731RH0CIoo",
        "outputId": "0d611c4a-9f8d-48a6-abcc-f8bf90bf1519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avant FWM : [ 4.5545931e+00  1.1845577e+00  3.4474282e+00 -7.8125382e-03\n",
            "  5.2828209e+01 -5.4075713e-03  2.5962763e+00  2.6907651e+00\n",
            "  2.6754749e+00 -1.6975038e-01]\n",
            "Après FWM : [ 9.3613759e-02  4.5933731e-02  8.8477530e-02 -1.6546519e-04\n",
            "  1.1535512e+00 -8.0005266e-05  9.2550516e-03  9.0150461e-03\n",
            "  8.3973967e-03 -8.9236075e-04]\n"
          ]
        }
      ],
      "source": [
        "#Vérification rapide (sanity check)\n",
        "print(\"Avant FWM :\", X_train_balanced[0, :10])\n",
        "print(\"Après FWM :\", X_train_fwm[0, :10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LmH6S6_Ef6K"
      },
      "source": [
        "### implémentattion du  swcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeOKRXd8Fmgi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UqmuhamCQSD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def swcc_single_batch(X_batch, window_size=5):\n",
        "    \"\"\"\n",
        "    Applique SWCC sur un batch de données.\n",
        "    X_batch: ndarray de forme (n_samples, n_features)\n",
        "    window_size: taille de la fenêtre glissante\n",
        "    \"\"\"\n",
        "    X_corrected = X_batch.copy()\n",
        "    n_samples, n_features = X_batch.shape\n",
        "\n",
        "    # Pour chaque feature (canal)\n",
        "    for i in range(n_features):\n",
        "        channel = X_batch[:, i]\n",
        "        corrected_channel = np.zeros_like(channel)\n",
        "\n",
        "        # Boucle glissante sur les échantillons\n",
        "        for j in range(n_samples):\n",
        "            start = max(0, j - window_size // 2)\n",
        "            end = min(n_samples, j + window_size // 2 + 1)\n",
        "            window = channel[start:end]\n",
        "\n",
        "            # Correction : centrer sur la moyenne locale\n",
        "            corrected_channel[j] = channel[j] - np.mean(window)\n",
        "\n",
        "        X_corrected[:, i] = corrected_channel\n",
        "\n",
        "    return X_corrected\n",
        "\n",
        "def apply_swcc_in_batches(X, batch_size=1024, window_size=5):\n",
        "    \"\"\"\n",
        "    Applique SWCC sur l'ensemble des données par batch pour économiser la RAM.\n",
        "    \"\"\"\n",
        "    n_samples = X.shape[0]\n",
        "    X_corrected = np.zeros_like(X)\n",
        "\n",
        "    for start in tqdm(range(0, n_samples, batch_size), desc=\"SWCC\"):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        X_corrected[start:end] = swcc_single_batch(X[start:end], window_size=window_size)\n",
        "    return X_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQhmy8cTElVO",
        "outputId": "2fa7df17-42a6-4138-c748-034bf4871cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SWCC: 100%|██████████| 3907/3907 [50:34<00:00,  1.29it/s]\n",
            "SWCC: 100%|██████████| 1063/1063 [13:40<00:00,  1.30it/s]\n",
            "SWCC: 100%|██████████| 1063/1063 [13:35<00:00,  1.30it/s]\n"
          ]
        }
      ],
      "source": [
        "# Application sur train / val / test\n",
        "X_train_swcc = apply_swcc_in_batches(X_train_balanced, batch_size=1024, window_size=5)\n",
        "X_val_swcc   = apply_swcc_in_batches(X_val_scaled,   batch_size=1024, window_size=5)\n",
        "X_test_swcc  = apply_swcc_in_batches(X_test_scaled,  batch_size=1024, window_size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMzR6fPEIKxJ"
      },
      "source": [
        "### **Modelisation CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VDRZ2X8EmHE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- 1. Définir un CNN générique ---\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_channels=1, num_classes=2):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "def train_model_clean(X_train, y_train, X_val, y_val, epochs=10, batch_size=64, lr=0.001):\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "    # --- Convertir les labels en int si ce n'est pas déjà fait ---\n",
        "    y_train = np.array(y_train).astype(int)\n",
        "    y_val   = np.array(y_val).astype(int)\n",
        "\n",
        "    # --- Convertir les données en Tensor ---\n",
        "    def prepare_tensor(X):\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "        if X_tensor.ndim == 2:\n",
        "            X_tensor = X_tensor.unsqueeze(1)  # (batch, 1, features)\n",
        "        return X_tensor\n",
        "\n",
        "    X_train_tensor = prepare_tensor(X_train)\n",
        "    X_val_tensor   = prepare_tensor(X_val)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    y_val_tensor   = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader    = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # --- Device ---\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SimpleCNN(input_channels=X_train_tensor.shape[1], num_classes=len(np.unique(y_train)))\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model = model.state_dict()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Entraînement ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train, total_train = 0, 0\n",
        "\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * X_batch.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += y_batch.size(0)\n",
        "            correct_train += (predicted == y_batch).sum().item()\n",
        "\n",
        "        train_acc = float(correct_train) / float(total_train)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        correct_val, total_val = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_val += y_batch.size(0)\n",
        "                correct_val += (predicted == y_batch).sum().item()\n",
        "\n",
        "        val_acc = float(correct_val) / float(total_val)\n",
        "\n",
        "        # --- Sauvegarder meilleur modèle ---\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "        # --- Print clair entre 0 et 1 ---\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/total_train:.4f} \"\n",
        "              f\"- Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxc-pl8pIuaT"
      },
      "source": [
        "### **CNN-1 : sur données normales**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABUy7Yl8RgG_",
        "outputId": "fd3ab39e-c90f-4e1c-e9fa-ebc2ab168e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "int64\n",
            "int64\n"
          ]
        }
      ],
      "source": [
        "# Assurer que les labels sont des entiers\n",
        "y_train_balanced = np.array(y_train_balanced).astype(int)\n",
        "y_val = np.array(y_val).astype(int)\n",
        "y_test = np.array(y_test).astype(int)  # si tu as un test set\n",
        "\n",
        "# Vérifier le type\n",
        "print(y_train_balanced.dtype)  # doit être int64\n",
        "print(y_val.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xFDcHr4YIdlr",
        "outputId": "97ba803d-c97c-4a20-cab1-9a3a000f1711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Loss: 0.1373 - Train Acc: 0.9518 - Val Acc: 63.9779\n",
            "Epoch 2/20 - Loss: 0.0832 - Train Acc: 0.9708 - Val Acc: 63.9564\n",
            "Epoch 3/20 - Loss: 0.0658 - Train Acc: 0.9765 - Val Acc: 63.9823\n",
            "Epoch 4/20 - Loss: 0.0562 - Train Acc: 0.9802 - Val Acc: 63.9532\n",
            "Epoch 5/20 - Loss: 0.0502 - Train Acc: 0.9826 - Val Acc: 63.9681\n",
            "Epoch 6/20 - Loss: 0.0461 - Train Acc: 0.9843 - Val Acc: 52.5729\n",
            "Epoch 7/20 - Loss: 0.0431 - Train Acc: 0.9854 - Val Acc: 63.9748\n",
            "Epoch 8/20 - Loss: 0.0413 - Train Acc: 0.9862 - Val Acc: 63.9672\n",
            "Epoch 9/20 - Loss: 0.0392 - Train Acc: 0.9871 - Val Acc: 63.9497\n",
            "Epoch 10/20 - Loss: 0.0380 - Train Acc: 0.9876 - Val Acc: 63.8980\n",
            "Epoch 11/20 - Loss: 0.0369 - Train Acc: 0.9880 - Val Acc: 63.9542\n",
            "Epoch 12/20 - Loss: 0.0357 - Train Acc: 0.9885 - Val Acc: 63.2816\n",
            "Epoch 13/20 - Loss: 0.0349 - Train Acc: 0.9889 - Val Acc: 63.3978\n",
            "Epoch 14/20 - Loss: 0.0340 - Train Acc: 0.9893 - Val Acc: 63.9715\n",
            "Epoch 15/20 - Loss: 0.0332 - Train Acc: 0.9896 - Val Acc: 60.4481\n",
            "Epoch 16/20 - Loss: 0.0324 - Train Acc: 0.9899 - Val Acc: 55.3309\n",
            "Epoch 17/20 - Loss: 0.0317 - Train Acc: 0.9902 - Val Acc: 63.9512\n",
            "Epoch 18/20 - Loss: 0.0314 - Train Acc: 0.9903 - Val Acc: 63.8051\n",
            "Epoch 19/20 - Loss: 0.0306 - Train Acc: 0.9905 - Val Acc: 63.3248\n",
            "Epoch 20/20 - Loss: 0.0304 - Train Acc: 0.9907 - Val Acc: 63.9350\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Entraînement des trois CNN ---\n",
        "# CNN-1 : sur données normales\n",
        "cnn1_model = train_model_v1(X_train_balanced, y_train_balanced, X_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOu-_FQxcOzr"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_full(model, X_test, y_test, batch_size=64):\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    # --- X ---\n",
        "    if hasattr(X_test, \"values\"):  # pandas DataFrame\n",
        "        X_test = X_test.values\n",
        "    X_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    if X_tensor.ndim == 2:\n",
        "        X_tensor = X_tensor.unsqueeze(1)\n",
        "\n",
        "    # --- y (ULTRA SAFE) ---\n",
        "    if hasattr(y_test, \"values\"):  # pandas DataFrame ou Series\n",
        "        y_test = y_test.values\n",
        "    y_test = np.array(y_test).squeeze().astype(int)\n",
        "    y_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y_batch.numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    TPR = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    FPR = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(f\"TPR (Recall): {TPR:.4f}\")\n",
        "    print(f\"FPR: {FPR:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    return acc, cm, f1, TPR, FPR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOrn7KstcbgV",
        "outputId": "418653cc-ac6c-4068-9a39-c2a2350b36ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9993\n",
            "F1-score: 0.9996\n",
            "TPR (Recall): 0.9993\n",
            "FPR: 0.1813\n",
            "Confusion Matrix:\n",
            "[[    158      35]\n",
            " [    754 1086877]]\n"
          ]
        }
      ],
      "source": [
        "# Après entraînement du modèle\n",
        "#cnn_model = train_model_clean(X_train, y_train, X_val, y_val, epochs=20)\n",
        "# Évaluation complète sur le test set\n",
        "acc, cm, f1, TPR, FPR = evaluate_model_full(cnn1_model, X_test_scaled, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAaLPBztI1ze"
      },
      "source": [
        "### **SWCC-CNN : sur données SWCC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__5uqWGzI6uA",
        "outputId": "6a7a480f-17c9-4c56-eb43-db9c891cb5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.3055 - Train Acc: 0.8727 - Val Acc: 61.2491\n",
            "Epoch 2/10 - Loss: 0.2581 - Train Acc: 0.8933 - Val Acc: 60.8000\n",
            "Epoch 3/10 - Loss: 0.2405 - Train Acc: 0.9021 - Val Acc: 59.6104\n",
            "Epoch 4/10 - Loss: 0.2291 - Train Acc: 0.9081 - Val Acc: 61.3665\n",
            "Epoch 5/10 - Loss: 0.2196 - Train Acc: 0.9132 - Val Acc: 60.1289\n",
            "Epoch 6/10 - Loss: 0.2128 - Train Acc: 0.9172 - Val Acc: 60.9723\n",
            "Epoch 7/10 - Loss: 0.2071 - Train Acc: 0.9202 - Val Acc: 60.3881\n",
            "Epoch 8/10 - Loss: 0.2028 - Train Acc: 0.9225 - Val Acc: 61.3153\n",
            "Epoch 9/10 - Loss: 0.1990 - Train Acc: 0.9246 - Val Acc: 60.0872\n",
            "Epoch 10/10 - Loss: 0.1952 - Train Acc: 0.9266 - Val Acc: 58.8576\n"
          ]
        }
      ],
      "source": [
        "# SWCC-CNN : sur données SWCC\n",
        "swcc_model = train_model_clean(X_train_swcc, y_train_balanced, X_val_swcc, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Gk3PRBl_koE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c77377-9399-47f0-df85-79b36e99b254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9196\n",
            "F1-score: 0.9581\n",
            "TPR (Recall): 0.9196\n",
            "FPR: 0.0363\n",
            "Confusion Matrix:\n",
            "[[    186       7]\n",
            " [  87406 1000225]]\n"
          ]
        }
      ],
      "source": [
        "acc, cm, f1, TPR, FPR = evaluate_model_full(swcc_model, X_test_swcc, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FUP2jK0_38B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68c3865-4701-4132-c165-5020ed6ba0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle sauvegardé dans : /content/drive/MyDrive/master SDIA/S3/Advanced Topics  Data Science/swcc_cnn_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Chemin complet dans Google Drive\n",
        "save_path = \"/content/drive/MyDrive/master SDIA/S3/Advanced Topics  Data Science/swcc_cnn_model.pth\"\n",
        "\n",
        "# Sauvegarde du modèle (state_dict recommandé)\n",
        "torch.save(swcc_model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Modèle sauvegardé dans : {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWKG4QyKI94s"
      },
      "source": [
        "### **FWM-CNN : sur données FWM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "collapsed": true,
        "id": "BwWjvKg-zAwS",
        "outputId": "98ac4964-1082-48fc-e644-3d15e1434500"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cnn1_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2329679041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mcnn1_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn1_model' is not defined"
          ]
        }
      ],
      "source": [
        "del cnn1_model\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sOSx2wbJDrz",
        "outputId": "4281df54-5611-4738-c43e-6d3c614b1c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Loss: 0.1463 - Train Acc: 0.9475 - Val Acc: 48.1689\n",
            "Epoch 2/10 - Loss: 0.0963 - Train Acc: 0.9645 - Val Acc: 63.9243\n",
            "Epoch 3/10 - Loss: 0.0779 - Train Acc: 0.9716 - Val Acc: 63.9805\n",
            "Epoch 4/10 - Loss: 0.0680 - Train Acc: 0.9755 - Val Acc: 63.9788\n",
            "Epoch 5/10 - Loss: 0.0616 - Train Acc: 0.9781 - Val Acc: 63.9781\n",
            "Epoch 6/10 - Loss: 0.0568 - Train Acc: 0.9798 - Val Acc: 63.9782\n",
            "Epoch 7/10 - Loss: 0.0538 - Train Acc: 0.9810 - Val Acc: 63.7691\n",
            "Epoch 8/10 - Loss: 0.0507 - Train Acc: 0.9822 - Val Acc: 63.9854\n",
            "Epoch 9/10 - Loss: 0.0479 - Train Acc: 0.9832 - Val Acc: 63.9748\n",
            "Epoch 10/10 - Loss: 0.0457 - Train Acc: 0.9842 - Val Acc: 63.5748\n"
          ]
        }
      ],
      "source": [
        "# FWM-CNN : sur données FWM\n",
        "fwm_model = train_model_clean(X_train_fwm, y_train_balanced, X_val_fwm, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E9dMpWXM2lG",
        "outputId": "4a9e4f5d-45e3-4029-ad4b-ffee9d6bba3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9935\n",
            "F1-score: 0.9967\n",
            "TPR (Recall): 0.9935\n",
            "FPR: 0.0311\n",
            "Confusion Matrix:\n",
            "[[    187       6]\n",
            " [   7065 1080566]]\n"
          ]
        }
      ],
      "source": [
        "acc, cm, f1, TPR, FPR = evaluate_model_full(fwm_model, X_test_fwm, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypIW2WJvmG97",
        "outputId": "381c1af4-ebd0-4641-a6d4-94faff9ddf71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modèle sauvegardé dans : /content/drive/MyDrive/master SDIA/S3/Advanced Topics  Data Science/fwm_cnn_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Chemin complet dans Google Drive\n",
        "save_path = \"/content/drive/MyDrive/master SDIA/S3/Advanced Topics  Data Science/fwm_cnn_model.pth\"\n",
        "\n",
        "# Sauvegarde du modèle (state_dict recommandé)\n",
        "torch.save(fwm_model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Modèle sauvegardé dans : {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSbN0WrnnsfE"
      },
      "outputs": [],
      "source": [
        "del fwm_model,X_test_fwm,X_val_fwm,X_train_fwm\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtPebUiopjaH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "E3iEj9cN6A2J",
        "Rxc-pl8pIuaT",
        "XWKG4QyKI94s"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
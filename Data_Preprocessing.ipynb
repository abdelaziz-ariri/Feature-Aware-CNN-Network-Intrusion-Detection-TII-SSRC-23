{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6312696,"sourceType":"datasetVersion","datasetId":3631110}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## üõ°Ô∏è TII-SSRC-23 Dataset ‚Äì Overview\n\nThe **TII-SSRC-23 Dataset** is a modern cybersecurity dataset designed for **AI-based Intrusion Detection and Prevention Systems (IDS/IPS)**. It contains labeled network traffic data representing both **benign activity** and **multiple types of cyberattacks**.\n\nThis dataset is suitable for **binary and multi-class classification**, **anomaly detection**, and **machine learning/deep learning experiments** in network security. It reflects **realistic and recent attack behaviors**, making it ideal for evaluating intelligent IDS/IPS models.\n","metadata":{}},{"cell_type":"markdown","source":"### ***Environment Setup***","metadata":{}},{"cell_type":"code","source":"# Cell 1: Install and import necessary libraries\n# -------------------------------------------------\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport os\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:36:43.235885Z","iopub.execute_input":"2026-01-10T10:36:43.237521Z","iopub.status.idle":"2026-01-10T10:36:43.242662Z","shell.execute_reply.started":"2026-01-10T10:36:43.237477Z","shell.execute_reply":"2026-01-10T10:36:43.241559Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"###   ***Data Loading and Initial Overview***","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nprint('Loading dataset... This may take some time. Please monitor the RAM usage at the top right corner.')\ndf = pd.read_csv('/kaggle/input/tii-ssrc-23/csv/data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:36:49.651174Z","iopub.execute_input":"2026-01-10T10:36:49.651571Z","iopub.status.idle":"2026-01-10T10:39:27.384377Z","shell.execute_reply.started":"2026-01-10T10:36:49.651543Z","shell.execute_reply":"2026-01-10T10:39:27.383179Z"}},"outputs":[{"name":"stdout","text":"Loading dataset... This may take some time. Please monitor the RAM usage at the top right corner.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:11:21.413597Z","iopub.execute_input":"2026-01-10T10:11:21.413897Z","iopub.status.idle":"2026-01-10T10:11:21.461507Z","shell.execute_reply.started":"2026-01-10T10:11:21.413871Z","shell.execute_reply":"2026-01-10T10:11:21.460668Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                   Flow ID        Src IP  Src Port  \\\n0   192.168.1.90-192.168.1.3-53930-64738-6  192.168.1.90   53930.0   \n1   192.168.1.3-192.168.1.90-64738-37700-6   192.168.1.3   64738.0   \n2      192.168.1.3-192.168.1.90-22-40854-6   192.168.1.3      22.0   \n3   192.168.1.70-192.168.1.3-55422-64738-6  192.168.1.70   55422.0   \n4  192.168.1.90-192.168.1.3-59658-64738-17  192.168.1.90   59658.0   \n\n         Dst IP  Dst Port  Protocol               Timestamp  Flow Duration  \\\n0   192.168.1.3     64738       6.0  01/01/1970 07:41:46 AM     52601173.0   \n1  192.168.1.90     37700       6.0  01/01/1970 07:41:46 AM    119106942.0   \n2  192.168.1.90     40854       6.0  01/01/1970 07:41:46 AM         5589.0   \n3   192.168.1.3     64738       6.0  01/01/1970 07:41:47 AM    118166562.0   \n4   192.168.1.3     64738      17.0  01/01/1970 07:41:50 AM    119988385.0   \n\n   Total Fwd Packet  Total Bwd packets  ...    Active Std  Active Max  \\\n0            1701.0             1793.0  ...  0.000000e+00         0.0   \n1              36.0               57.0  ...  3.416174e+06  19996926.0   \n2               1.0                1.0  ...  0.000000e+00         0.0   \n3            3932.0             4196.0  ...  0.000000e+00         0.0   \n4              25.0             6795.0  ...  0.000000e+00         0.0   \n\n   Active Min  Idle Mean     Idle Std   Idle Max   Idle Min   Label  \\\n0         0.0        0.0     0.000000        0.0        0.0  Benign   \n1  14078617.0  5001511.0  1737.400069  5003516.0  5000449.0  Benign   \n2         0.0        0.0     0.000000        0.0        0.0  Benign   \n3         0.0        0.0     0.000000        0.0        0.0  Benign   \n4         0.0        0.0     0.000000        0.0        0.0  Benign   \n\n   Traffic Type  Traffic Subtype  \n0         Audio            Audio  \n1         Audio            Audio  \n2         Audio            Audio  \n3         Audio            Audio  \n4         Audio            Audio  \n\n[5 rows x 86 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Flow ID</th>\n      <th>Src IP</th>\n      <th>Src Port</th>\n      <th>Dst IP</th>\n      <th>Dst Port</th>\n      <th>Protocol</th>\n      <th>Timestamp</th>\n      <th>Flow Duration</th>\n      <th>Total Fwd Packet</th>\n      <th>Total Bwd packets</th>\n      <th>...</th>\n      <th>Active Std</th>\n      <th>Active Max</th>\n      <th>Active Min</th>\n      <th>Idle Mean</th>\n      <th>Idle Std</th>\n      <th>Idle Max</th>\n      <th>Idle Min</th>\n      <th>Label</th>\n      <th>Traffic Type</th>\n      <th>Traffic Subtype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192.168.1.90-192.168.1.3-53930-64738-6</td>\n      <td>192.168.1.90</td>\n      <td>53930.0</td>\n      <td>192.168.1.3</td>\n      <td>64738</td>\n      <td>6.0</td>\n      <td>01/01/1970 07:41:46 AM</td>\n      <td>52601173.0</td>\n      <td>1701.0</td>\n      <td>1793.0</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Benign</td>\n      <td>Audio</td>\n      <td>Audio</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>192.168.1.3-192.168.1.90-64738-37700-6</td>\n      <td>192.168.1.3</td>\n      <td>64738.0</td>\n      <td>192.168.1.90</td>\n      <td>37700</td>\n      <td>6.0</td>\n      <td>01/01/1970 07:41:46 AM</td>\n      <td>119106942.0</td>\n      <td>36.0</td>\n      <td>57.0</td>\n      <td>...</td>\n      <td>3.416174e+06</td>\n      <td>19996926.0</td>\n      <td>14078617.0</td>\n      <td>5001511.0</td>\n      <td>1737.400069</td>\n      <td>5003516.0</td>\n      <td>5000449.0</td>\n      <td>Benign</td>\n      <td>Audio</td>\n      <td>Audio</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>192.168.1.3-192.168.1.90-22-40854-6</td>\n      <td>192.168.1.3</td>\n      <td>22.0</td>\n      <td>192.168.1.90</td>\n      <td>40854</td>\n      <td>6.0</td>\n      <td>01/01/1970 07:41:46 AM</td>\n      <td>5589.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Benign</td>\n      <td>Audio</td>\n      <td>Audio</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192.168.1.70-192.168.1.3-55422-64738-6</td>\n      <td>192.168.1.70</td>\n      <td>55422.0</td>\n      <td>192.168.1.3</td>\n      <td>64738</td>\n      <td>6.0</td>\n      <td>01/01/1970 07:41:47 AM</td>\n      <td>118166562.0</td>\n      <td>3932.0</td>\n      <td>4196.0</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Benign</td>\n      <td>Audio</td>\n      <td>Audio</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>192.168.1.90-192.168.1.3-59658-64738-17</td>\n      <td>192.168.1.90</td>\n      <td>59658.0</td>\n      <td>192.168.1.3</td>\n      <td>64738</td>\n      <td>17.0</td>\n      <td>01/01/1970 07:41:50 AM</td>\n      <td>119988385.0</td>\n      <td>25.0</td>\n      <td>6795.0</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Benign</td>\n      <td>Audio</td>\n      <td>Audio</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 86 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:11:21.462441Z","iopub.execute_input":"2026-01-10T10:11:21.462770Z","iopub.status.idle":"2026-01-10T10:11:21.471861Z","shell.execute_reply.started":"2026-01-10T10:11:21.462747Z","shell.execute_reply":"2026-01-10T10:11:21.470858Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Index(['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol',\n       'Timestamp', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n       'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n       'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n       'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n       'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg',\n       'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg',\n       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n       'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n       'Idle Min', 'Label', 'Traffic Type', 'Traffic Subtype'],\n      dtype='object')"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### ***Data Cleaning***","metadata":{}},{"cell_type":"code","source":"# Cell 3: A. Data Cleaning\n# ============================================================================\ndef clean_data(df):\n    \"\"\"\n    Clean data according to article methodology\n    \"\"\"\n    print(\"üßπ Step 1: Data Cleaning\")\n    # Create a copy\n    df_clean = df.copy()\n    # 1. Remove columns specified in the article\n    columns_to_remove = [\n        'Flow ID',      # Identifiant unique - pas d'information discriminante\n        'Src IP',       # Adresse IP source - trop sp√©cifique, cause d'overfitting\n        'Src Port',     # Port source - pas pertinent pour classification g√©n√©rale\n        'Dst IP',       # Adresse IP destination - trop sp√©cifique\n       'Dst Port',     # Port destination - pas pertinent\n       'Timestamp',    # Horodatage - non pertinent pour classification\n    ]\n    \n    # Remove only existing columns\n    existing_cols = [col for col in columns_to_remove if col in df_clean.columns]\n    if existing_cols:\n        df_clean = df_clean.drop(columns=existing_cols)\n        print(f\"   ‚úì Removed columns: {existing_cols}\")\n    \n    # 2. Check for missing values\n    missing_values = df_clean.isnull().sum().sum()\n    if missing_values > 0:\n        print(f\"   ‚ö†Ô∏è  Missing values detected: {missing_values}\")\n        # Show columns with missing values\n        missing_cols = df_clean.columns[df_clean.isnull().any()].tolist()\n        print(f\"   Columns with missing values: {missing_cols[:10]}\")\n    else:\n        print(f\"   ‚úì No missing values detected\")\n    \n    # 3. Remove duplicates\n    initial_rows = len(df_clean)\n    df_clean = df_clean.drop_duplicates()\n    duplicates_removed = initial_rows - len(df_clean)\n    if duplicates_removed > 0:\n        print(f\"   ‚úì Duplicates removed: {duplicates_removed}\")\n    \n    # 4. Data type information\n    print(f\"\\n   üìã Data types:\")\n    dtypes_summary = df_clean.dtypes.value_counts()\n    for dtype, count in dtypes_summary.items():\n        print(f\"   {dtype}: {count} columns\")\n    \n    return df_clean\n\n# Apply cleaning\ndf_clean = clean_data(df)\nprint(f\"\\n‚úÖ Cleaning completed. New shape: {df_clean.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:40:01.203455Z","iopub.execute_input":"2026-01-10T10:40:01.205169Z","iopub.status.idle":"2026-01-10T10:41:31.142312Z","shell.execute_reply.started":"2026-01-10T10:40:01.205111Z","shell.execute_reply":"2026-01-10T10:41:31.141138Z"}},"outputs":[{"name":"stdout","text":"üßπ Step 1: Data Cleaning\n   ‚úì Removed columns: ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Timestamp']\n   ‚úì No missing values detected\n   ‚úì Duplicates removed: 1404612\n\n   üìã Data types:\n   float64: 77 columns\n   object: 3 columns\n\n‚úÖ Cleaning completed. New shape: (7252155, 80)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df_clean.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T09:14:46.147760Z","iopub.execute_input":"2026-01-10T09:14:46.148086Z","iopub.status.idle":"2026-01-10T09:14:46.154965Z","shell.execute_reply.started":"2026-01-10T09:14:46.148063Z","shell.execute_reply":"2026-01-10T09:14:46.153991Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['Protocol', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n       'Total Length of Fwd Packet', 'Total Length of Bwd Packet',\n       'Fwd Packet Length Max', 'Fwd Packet Length Min',\n       'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n       'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length',\n       'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s',\n       'Packet Length Min', 'Packet Length Max', 'Packet Length Mean',\n       'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n       'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n       'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio',\n       'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg',\n       'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg',\n       'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg',\n       'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets',\n       'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes',\n       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n       'Idle Min', 'Label', 'Traffic Type', 'Traffic Subtype'],\n      dtype='object')"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### ***Data Split***","metadata":{}},{"cell_type":"code","source":"FEATURES = [\n    col for col in df_clean.columns\n    if col not in ['Label', 'Traffic Type', 'Traffic Subtype']\n]\n\nX = df_clean[FEATURES]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:41:38.781075Z","iopub.execute_input":"2026-01-10T10:41:38.781464Z","iopub.status.idle":"2026-01-10T10:41:40.573840Z","shell.execute_reply.started":"2026-01-10T10:41:38.781435Z","shell.execute_reply":"2026-01-10T10:41:40.572815Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def stratified_split(X, y, test_size=0.15, val_size=0.15, random_state=42):\n    X_tmp, X_test, y_tmp, y_test = train_test_split(\n        X, y,\n        test_size=test_size,\n        stratify=y,\n        random_state=random_state\n    )\n\n    val_ratio = val_size / (1 - test_size)\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_tmp, y_tmp,\n        test_size=val_ratio,\n        stratify=y_tmp,\n        random_state=random_state\n    )\n\n    return X_train, X_val, X_test, y_train, y_val, y_test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:41:42.349987Z","iopub.execute_input":"2026-01-10T10:41:42.350381Z","iopub.status.idle":"2026-01-10T10:41:42.356867Z","shell.execute_reply.started":"2026-01-10T10:41:42.350351Z","shell.execute_reply":"2026-01-10T10:41:42.355679Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def save_dataset(base_path, X_train, X_val, X_test, y_train, y_val, y_test):\n    os.makedirs(base_path, exist_ok=True)\n\n    X_train.to_csv(f\"{base_path}/X_train.csv\", index=False)\n    X_val.to_csv(f\"{base_path}/X_val.csv\", index=False)\n    X_test.to_csv(f\"{base_path}/X_test.csv\", index=False)\n\n    y_train.to_csv(f\"{base_path}/y_train.csv\", index=False)\n    y_val.to_csv(f\"{base_path}/y_val.csv\", index=False)\n    y_test.to_csv(f\"{base_path}/y_test.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:41:45.876338Z","iopub.execute_input":"2026-01-10T10:41:45.877349Z","iopub.status.idle":"2026-01-10T10:41:45.883562Z","shell.execute_reply.started":"2026-01-10T10:41:45.877312Z","shell.execute_reply":"2026-01-10T10:41:45.882016Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"#### ***1-Dataset BINAIRE***","metadata":{}},{"cell_type":"code","source":"y_binary = df_clean['Label']\n\nXb_train, Xb_val, Xb_test, yb_train, yb_val, yb_test = stratified_split(\n    X, y_binary\n)\n\nsave_dataset(\n    \"dataset/dataset_binary\",\n    Xb_train, Xb_val, Xb_test,\n    yb_train, yb_val, yb_test\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T09:15:03.455462Z","iopub.execute_input":"2026-01-10T09:15:03.455820Z","iopub.status.idle":"2026-01-10T09:23:40.864834Z","shell.execute_reply.started":"2026-01-10T09:15:03.455792Z","shell.execute_reply":"2026-01-10T09:23:40.863786Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"### ***Dataset TYPE (8 classes)***","metadata":{}},{"cell_type":"code","source":"y_type = df_clean['Traffic Type']\n\nXt_train, Xt_val, Xt_test, yt_train, yt_val, yt_test = stratified_split(\n    X, y_type\n)\n\nsave_dataset(\n    \"dataset/dataset_type\",\n     Xt_train, Xt_val, Xt_test,\n     yt_train, yt_val, yt_test\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:15:31.510637Z","iopub.execute_input":"2026-01-10T10:15:31.510951Z","iopub.status.idle":"2026-01-10T10:24:35.683110Z","shell.execute_reply.started":"2026-01-10T10:15:31.510930Z","shell.execute_reply":"2026-01-10T10:24:35.681909Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#### ***Dataset SUBTYPE (32 classes)***","metadata":{}},{"cell_type":"code","source":"y_subtype = df_clean['Traffic Subtype']\n\nXs_train, Xs_val, Xs_test, ys_train, ys_val, ys_test = stratified_split(\n    X, y_subtype\n)\nsave_dataset(\n    \"dataset/dataset_subtype\",\n    Xs_train, Xs_val, Xs_test,\n    ys_train, ys_val, ys_test\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:41:51.090796Z","iopub.execute_input":"2026-01-10T10:41:51.091147Z","iopub.status.idle":"2026-01-10T10:50:57.581735Z","shell.execute_reply.started":"2026-01-10T10:41:51.091119Z","shell.execute_reply":"2026-01-10T10:50:57.580134Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\n    \"dataset_subtype\",          # nom du zip (sans .zip)\n    \"zip\",\n    \"dataset/dataset_subtype\"   # dossier √† compresser\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T10:54:43.246089Z","iopub.execute_input":"2026-01-10T10:54:43.246765Z","iopub.status.idle":"2026-01-10T10:57:06.369161Z","shell.execute_reply.started":"2026-01-10T10:54:43.246706Z","shell.execute_reply":"2026-01-10T10:57:06.368068Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/dataset_subtype.zip'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}